{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import json\n",
    "\n",
    "import folium\n",
    "import geohash\n",
    "import geopandas\n",
    "import holoviews as hv\n",
    "import hvplot.xarray  # noqa: F401\n",
    "import numpy as np\n",
    "import odc.geo.xr\n",
    "import pystac\n",
    "import rioxarray  # noqa: F401\n",
    "import s3fs\n",
    "import shapely\n",
    "import xarray as xr\n",
    "from dea_tools.spatial import xr_rasterize, xr_vectorize\n",
    "from fsspec.implementations.http import HTTPFileSystem\n",
    "from holoviews import opts\n",
    "from odc.stac import configure_rio, load\n",
    "\n",
    "# Hacking imports from parent directory :-)\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "sys.path.append(os.path.dirname(NOTEBOOK_DIR))\n",
    "\n",
    "from utils import get_rgb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "if odc.stac.__version__ != \"0.3.6\":\n",
    "    raise Exception(f\"You need to use odc.stac version 0.3.6 or greater. You have {odc.stac.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_uri = \"s3://files.auspatious.com/hsi_example/TD1_004930_20230205_L2A_20230224_03001065_COG.stac-item.json\"\n",
    "\n",
    "# Open S3 object as a file using s3fs\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "with s3.open(s3_uri, \"rt\") as f:\n",
    "    stac_dict = json.load(f)\n",
    "item = pystac.read_dict(stac_dict)\n",
    "\n",
    "# Optionally select a subset, so it doesn't take a long time\n",
    "eo_bands_subset = item.assets[\"reflectance\"].extra_fields[\"eo:bands\"]\n",
    "\n",
    "# Load the data, telling rasterio to not sign requests\n",
    "configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    "    AWS_S3_ENDPOINT=\"s3.ap-southeast-2.amazonaws.com\",\n",
    ")\n",
    "ds = load(\n",
    "    [item],\n",
    "    measurements=[i[\"name\"] for i in eo_bands_subset],\n",
    "    chunks={\"bands\": 1, \"longitude\": 1200, \"latitude\": 1200}\n",
    ")\n",
    "\n",
    "# No need for time\n",
    "ds = ds.squeeze(\"time\")\n",
    "\n",
    "# Stack up the bands, so we have a multi-dimensional raster instead\n",
    "ds_stacked = ds.to_array(\"bands\")\n",
    "\n",
    "# Replace the original ds object with a nice indexed one\n",
    "bands = list([float(i[\"description\"]) for i in eo_bands_subset])\n",
    "bands.sort()  # This is pretty dangerous... let's assume the .tif has bands in the right order!\n",
    "ds = ds_stacked.assign_coords(bands=bands).to_dataset(name=\"reflectance\")\n",
    "\n",
    "# mask 0 as nan\n",
    "ds = ds.where(ds != 0)\n",
    "\n",
    "# Load all the data. Should take less than 2 minutes\n",
    "ds = ds.compute()\n",
    "\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a water layer\n",
    "# Picked values from here https://en.wikipedia.org/wiki/Normalized_difference_water_index\n",
    "green = ds.reflectance.sel(bands=559, method=\"nearest\").astype(\"float32\")\n",
    "nir = ds.reflectance.sel(bands=864, method=\"nearest\").astype(\"float32\")\n",
    "\n",
    "water = ((green - nir) / (green + nir)) > 0.2\n",
    "ds[\"water\"] = water.fillna(float(\"nan\")).where(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.water.hvplot(aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIN_AREA = 80  # Hectares\n",
    "\n",
    "def add_geohash(row):\n",
    "    return geohash.encode(row.geometry.centroid.y, row.geometry.centroid.x, precision=9)\n",
    "\n",
    "    \n",
    "# Create polygons from the water layer\n",
    "water_polygons = xr_vectorize(ds.water, crs=\"epsg:4326\", mask=ds.water.values==1)\n",
    "water_polygons[\"area\"] = water_polygons.to_crs(\"epsg:3577\").area / 10000\n",
    "\n",
    "# Drop geopandas rows where the area is less than MIN_AREA\n",
    "water_polygons = water_polygons.drop(water_polygons[water_polygons['area'] < MIN_AREA].index)\n",
    "\n",
    "# Compute a geohash for each polygon at level 9\n",
    "geohashes = []\n",
    "for _, row in water_polygons.iterrows():\n",
    "    geohashes.append(add_geohash(row))\n",
    "\n",
    "water_polygons[\"geohash\"] = geohashes\n",
    "\n",
    "# Add an ID row\n",
    "water_polygons['id'] = range(1, water_polygons.shape[0] + 1)\n",
    "\n",
    "# Show us what we've got\n",
    "print(f\"Found {water_polygons.shape[0]} water polygons that are larger than {MIN_AREA} hectare(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the water layer on an interactive map\n",
    "\n",
    "# Reduce the polygons by a small amount (in degrees)\n",
    "# 0.001 is around 100 m\n",
    "SHRINK_AMOUNT = 0.001\n",
    "\n",
    "m = folium.Map(control_scale=True, tiles=None)\n",
    "\n",
    "for _, row in water_polygons.iterrows():\n",
    "    geojson = folium.GeoJson(\n",
    "        data=json.dumps(shapely.geometry.mapping(row.geometry.buffer(-1 * SHRINK_AMOUNT))),\n",
    "        style_function=lambda x: {\"fillColor\": \"blue\", \"Color\": \"blue\"},\n",
    "        tooltip=f\"{row.geohash}\"\n",
    "    )\n",
    "    folium.Popup(f\"<p><strong>geohash:</strong> {row.geohash}<br><strong>area:</strong> {row['area']:.3f} Ha</p>\").add_to(\n",
    "        geojson\n",
    "    )\n",
    "    geojson.add_to(m)\n",
    "\n",
    "# Zoom map\n",
    "m.fit_bounds(ds.odc.map_bounds())\n",
    "\n",
    "tile = folium.TileLayer(\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name=\"Esri Satellite\",\n",
    "    control=True,\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rasterise the polygons again, so we can join on the geohash later\n",
    "# First shrink them by SHRINK_AMOUNT\n",
    "water_polygons.geometry = water_polygons.geometry.buffer(-1 * SHRINK_AMOUNT)\n",
    "water_raster = xr_rasterize(water_polygons, ds, attribute_col=\"id\", crs=\"epsg:4326\")\n",
    "\n",
    "# Join the rasterised polygons to the dataset\n",
    "ds[\"id\"] = xr.DataArray(water_raster, dims=(\"latitude\", \"longitude\"))\n",
    "\n",
    "# Create another empty array of strings\n",
    "ds[\"geohash\"] = xr.DataArray(\n",
    "      np.full((ds.latitude.size, ds.longitude.size), \"\", dtype=\"U9\"),\n",
    "      dims=(\"latitude\", \"longitude\"),\n",
    ")\n",
    "\n",
    "for _, row in water_polygons.iterrows():\n",
    "   # I think 'where' works the opposite of what you'd expect\n",
    "   ds[\"geohash\"] = ds.geohash.where(ds.id != row.id, row.geohash)\n",
    "\n",
    "# Mask the empty values\n",
    "ds[\"geohash\"] = ds.geohash.where(ds.geohash != \"\", drop=False)\n",
    "del ds[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "means = ds.groupby(\"geohash\").mean()\n",
    "std_dev = ds.groupby(\"geohash\").std()\n",
    "min = ds.groupby(\"geohash\").min()\n",
    "max = ds.groupby(\"geohash\").max()\n",
    "\n",
    "# Create a new dataset with the mean, standard deviation, min and max values\n",
    "# for each geohash\n",
    "water_summaries = xr.Dataset(\n",
    "    {\n",
    "        \"mean\": means.reflectance,\n",
    "        \"std_dev\": std_dev.reflectance,\n",
    "        \"min\": min.reflectance,\n",
    "        \"max\": max.reflectance,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and std_dev plots\n",
    "color_cycle = hv.Cycle(\"Category20\")\n",
    "\n",
    "plots = []\n",
    "for geohash in water_summaries.geohash.values:\n",
    "    row = water_summaries.sel(geohash=geohash)\n",
    "\n",
    "    plots.append(\n",
    "        (\n",
    "            hv.Spread(\n",
    "                row,\n",
    "                vdims=[\"mean\", \"std_dev\", \"std_dev\"],\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "            * hv.Curve(\n",
    "                row,\n",
    "                vdims=\"mean\",\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "hv.Layout(plots).opts(\n",
    "    opts.Spread(color=color_cycle, show_legend=True),\n",
    "    opts.Curve(color=color_cycle, show_legend=True),\n",
    "    opts.Overlay(\n",
    "        show_title=True, frame_width=200, frame_height=50, show_legend=False, yaxis=None\n",
    "    ),\n",
    ").cols(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absorption depth, to be plotted per geohash\n",
    "absorption = 627\n",
    "reference_band = 560\n",
    "reference_band2 = 648\n",
    "\n",
    "absorption = ds.reflectance.sel(bands=absorption, method = 'nearest')\n",
    "reference1= ds.reflectance.sel(bands=reference_band, method = 'nearest')\n",
    "reference2 = ds.reflectance.sel(bands=reference_band2, method = 'nearest')\n",
    "ds[\"absorption_depth\"] = (reference1 + reference2)/2 - absorption\n",
    "\n",
    "# Simplify to a summary dataset, removing the bands dimension and reflectance data\n",
    "ds_summary = ds.drop_dims(\"bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Violin plots grouped by geohash\n",
    "ds_summary.hvplot.violin(\n",
    "    y=\"absorption_depth\",\n",
    "    by=\"geohash\",\n",
    ").opts(\n",
    "    opts.Violin(\n",
    "        width=800,\n",
    "        height=600,\n",
    "        xrotation=45,\n",
    "        show_legend=False,\n",
    "        title=\"Absorption Depth\",\n",
    "        # ylim=(-0.02, 0.03),\n",
    "        violin_fill_color='absorption_depth',\n",
    "        cmap = 'Spectral_r',\n",
    "        # clim = (0, 0.02),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below here we're going to select water bodies (geohashes) by thresholding\n",
    "# the absorption depth.\n",
    "\n",
    "geohash_absorption_depths = ds_summary.groupby(\"geohash\").mean()\n",
    "\n",
    "geohash_absorption_depths.hvplot(\n",
    "    x=\"geohash\",\n",
    "    y=\"absorption_depth\",\n",
    "    kind=\"scatter\",\n",
    "    title=\"Mean absorption depth\",\n",
    "    color=\"absorption_depth\",\n",
    "    cmap = 'magma_r',\n",
    "    # Line color\n",
    "    line_color=\"grey\",\n",
    "    size=40,\n",
    "    xaxis=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_d_gt_001 = geohash_absorption_depths.where(geohash_absorption_depths.absorption_depth < 1000, drop=True)\n",
    "high_absv = list(abs_d_gt_001.geohash.values)\n",
    "\n",
    "# Mean and std_dev plots\n",
    "color_cycle = hv.Cycle(\"Category20\")\n",
    "\n",
    "plots = []\n",
    "for geohash in high_absv:\n",
    "    row = water_summaries.sel(geohash=geohash)\n",
    "\n",
    "    plots.append(\n",
    "        (\n",
    "            hv.Spread(\n",
    "                row,\n",
    "                vdims=[\"mean\", \"std_dev\", \"std_dev\"],\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "            * hv.Curve(\n",
    "                row,\n",
    "                vdims=\"mean\",\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add a mean of all waterbodies plot too\n",
    "mean_all = water_summaries.mean(\"geohash\")\n",
    "plots.append(\n",
    "    (\n",
    "        hv.Spread(\n",
    "            mean_all,\n",
    "            vdims=[\"mean\", \"std_dev\", \"std_dev\"],\n",
    "            label=f\"all\"\n",
    "        )\n",
    "        * hv.Curve(\n",
    "            mean_all,\n",
    "            vdims=\"mean\",\n",
    "            label=f\"all\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "hv.Overlay(plots).opts(\n",
    "    opts.Spread(color=color_cycle, show_legend=True),\n",
    "    opts.Curve(color=color_cycle, show_legend=True),\n",
    "    opts.Overlay(\n",
    "        show_title=True, frame_width=600, frame_height=300, show_legend=True, yaxis=None\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alex Test Environment",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
