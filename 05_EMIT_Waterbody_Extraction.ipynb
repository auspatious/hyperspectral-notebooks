{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We're using Shapely features, but on EASI PyGEOS is still installed\n",
    "# So this needs to happen\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas\n",
    "\n",
    "import hvplot.xarray  # noqa: F401\n",
    "import numpy as np\n",
    "from fsspec.implementations.http import HTTPFileSystem\n",
    "from dea_tools.spatial import xr_vectorize\n",
    "import geohash\n",
    "import folium\n",
    "import odc.geo.xr\n",
    "from dea_tools.spatial import xr_rasterize\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import xarray as xr\n",
    "import json\n",
    "import shapely\n",
    "\n",
    "from emit_tools import emit_xarray\n",
    "from utils import get_rgb_dataset, get_earthdata_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterbody Extraction\n",
    "\n",
    "This notebook is a worked example. The goal of the analysis is to identify waterbodies that\n",
    "may have an algal bloom. To do this, we need to identify water bodies, examine their spectra\n",
    "and then calculate absorption depth before using a threshold to select waterbodies with high\n",
    "values.\n",
    "\n",
    "## Load data\n",
    "\n",
    "First we load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See README.md for instructions on how to get an Earthdata token\n",
    "token = get_earthdata_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loading data can take around 3-4 minutes on a 100 Mbps connection\n",
    "\n",
    "# Refer to the README.md for instructions on how to find granule IDs\n",
    "granule = \"EMIT_L2A_RFL_001_20230131T221923_2303114_008\"  # Lake Charm\n",
    "\n",
    "s3_url = \"s3://lp-prod-protected/EMITL2ARFL.001/\" + granule + \"/\" + granule + \".nc\"\n",
    "http_url = s3_url.replace(\"s3://\", \"https://data.lpdaac.earthdatacloud.nasa.gov/\")\n",
    "\n",
    "fs = HTTPFileSystem(headers={\n",
    "    \"Authorization\": f\"bearer {token}\"\n",
    "})\n",
    "ds = emit_xarray(fs.open(http_url))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "Next we clean up the empty bands, before creating a simple water/not-water\n",
    "layer using the normalised-difference wetness index and bands that had\n",
    "high or low values over water as identified in the previous animations notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up empty bands.\n",
    "ds = ds.fillna(np.nan).where(ds.reflectance!=-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a water layer\n",
    "high = ds.reflectance.sel(bands=450, method=\"nearest\")\n",
    "low = ds.reflectance.sel(bands=1275, method=\"nearest\")\n",
    "\n",
    "water = ((high - low) / (high + low)) > 0\n",
    "ds[\"water\"] = water.fillna(float(\"nan\")).where(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.water.hvplot(aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and creating IDs\n",
    "\n",
    "First, we want to filter by area so we only have large waterbodies. We\n",
    "do this using projected coordinates, rather than latitude/longitudes.\n",
    "\n",
    "Next we compute a geohash of the centroid of each waterbody, which can be\n",
    "used to help give a label to the waterbody, without needing to know the\n",
    "name of it.\n",
    "\n",
    "Note that we shrink the waterbody by a small amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIN_AREA = 80  # Hectares\n",
    "\n",
    "def add_geohash(row):\n",
    "    return geohash.encode(row.geometry.centroid.y, row.geometry.centroid.x, precision=9)\n",
    "\n",
    "    \n",
    "# Create polygons from the water layer\n",
    "water_polygons = xr_vectorize(ds.water, crs=\"epsg:4326\", mask=ds.water.values==1)\n",
    "water_polygons[\"area\"] = water_polygons.to_crs(\"epsg:3577\").area / 10000\n",
    "\n",
    "# Drop geopandas rows where the area is less than MIN_AREA\n",
    "water_polygons = water_polygons.drop(water_polygons[water_polygons['area'] < MIN_AREA].index)\n",
    "\n",
    "# Compute a geohash for each polygon at level 9\n",
    "geohashes = []\n",
    "for _, row in water_polygons.iterrows():\n",
    "    geohashes.append(add_geohash(row))\n",
    "\n",
    "water_polygons[\"geohash\"] = geohashes\n",
    "\n",
    "# Add an ID row\n",
    "water_polygons['id'] = range(1, water_polygons.shape[0] + 1)\n",
    "\n",
    "# Show us what we've got\n",
    "print(f\"Found {water_polygons.shape[0]} water polygons that are larger than {MIN_AREA} hectare(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the water layer on an interactive map\n",
    "\n",
    "# Reduce the polygons by a small amount (in degrees)\n",
    "# 0.001 is around 100 m\n",
    "SHRINK_AMOUNT = 0.001\n",
    "\n",
    "m = folium.Map(control_scale=True, tiles=None)\n",
    "\n",
    "for _, row in water_polygons.iterrows():\n",
    "    geojson = folium.GeoJson(\n",
    "        data=json.dumps(shapely.geometry.mapping(row.geometry.buffer(-1 * SHRINK_AMOUNT))),\n",
    "        style_function=lambda x: {\"fillColor\": \"blue\", \"Color\": \"blue\"},\n",
    "        tooltip=f\"{row.geohash}\"\n",
    "    )\n",
    "    folium.Popup(f\"<p><strong>geohash:</strong> {row.geohash}<br><strong>area:</strong> {row['area']:.3f} Ha</p>\").add_to(\n",
    "        geojson\n",
    "    )\n",
    "    geojson.add_to(m)\n",
    "\n",
    "# Zoom map\n",
    "m.fit_bounds(ds.odc.map_bounds())\n",
    "\n",
    "tile = folium.TileLayer(\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name=\"Esri Satellite\",\n",
    "    control=True,\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rasterise the polygons again, so we can join on the geohash later\n",
    "# First shrink them by SHRINK_AMOUNT\n",
    "water_polygons.geometry = water_polygons.geometry.buffer(-1 * SHRINK_AMOUNT)\n",
    "water_raster = xr_rasterize(water_polygons, ds, attribute_col=\"id\", crs=\"epsg:4326\")\n",
    "\n",
    "# Join the rasterised polygons to the dataset\n",
    "ds[\"id\"] = xr.DataArray(water_raster, dims=(\"latitude\", \"longitude\"))\n",
    "\n",
    "# Create another empty array of strings\n",
    "ds[\"geohash\"] = xr.DataArray(\n",
    "      np.full((ds.latitude.size, ds.longitude.size), \"\", dtype=\"U9\"),\n",
    "      dims=(\"latitude\", \"longitude\"),\n",
    ")\n",
    "\n",
    "for _, row in water_polygons.iterrows():\n",
    "   # I think 'where' works the opposite of what you'd expect\n",
    "   ds[\"geohash\"] = ds.geohash.where(ds.id != row.id, row.geohash)\n",
    "\n",
    "# Mask the empty values\n",
    "ds[\"geohash\"] = ds.geohash.where(ds.geohash != \"\", drop=False)\n",
    "del ds[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate summaries\n",
    "\n",
    "This next section creates summary values per waterbody (geohash).\n",
    "\n",
    "These will help us understand the average response and variability of\n",
    "the waterbody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "means = ds.groupby(\"geohash\").mean()\n",
    "std_dev = ds.groupby(\"geohash\").std()\n",
    "min = ds.groupby(\"geohash\").min()\n",
    "max = ds.groupby(\"geohash\").max()\n",
    "\n",
    "# Create a new dataset with the mean, standard deviation, min and max values\n",
    "# for each geohash\n",
    "water_summaries = xr.Dataset(\n",
    "    {\n",
    "        \"mean\": means.reflectance,\n",
    "        \"std_dev\": std_dev.reflectance,\n",
    "        \"min\": min.reflectance,\n",
    "        \"max\": max.reflectance,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and std_dev plots\n",
    "color_cycle = hv.Cycle(\"Category20\")\n",
    "\n",
    "plots = []\n",
    "for geohash in water_summaries.geohash.values:\n",
    "    row = water_summaries.sel(geohash=geohash)\n",
    "\n",
    "    plots.append(\n",
    "        (\n",
    "            hv.Spread(\n",
    "                row,\n",
    "                vdims=[\"mean\", \"std_dev\", \"std_dev\"],\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "            * hv.Curve(\n",
    "                row,\n",
    "                vdims=\"mean\",\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "hv.Layout(plots).opts(\n",
    "    opts.Spread(color=color_cycle, show_legend=True),\n",
    "    opts.Curve(color=color_cycle, show_legend=True),\n",
    "    opts.Overlay(\n",
    "        show_title=True, frame_width=200, frame_height=50, show_legend=False, yaxis=None\n",
    "    ),\n",
    ").cols(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absorption depth\n",
    "\n",
    "Now we calculate the absorption depth for each waterbody. This is done\n",
    "on the underlying reflectance values over three different bands, and not\n",
    "on the summary data. This means we can use violin plots to further\n",
    "understand the variability of this new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absorption depth, to be plotted per geohash\n",
    "absorption = 627\n",
    "reference_band = 560\n",
    "reference_band2 = 648\n",
    "\n",
    "absorption = ds.reflectance.sel(bands=absorption, method = 'nearest')\n",
    "reference1= ds.reflectance.sel(bands=reference_band, method = 'nearest')\n",
    "reference2 = ds.reflectance.sel(bands=reference_band2, method = 'nearest')\n",
    "ds[\"absorption_depth\"] = (reference1 + reference2)/2 - absorption\n",
    "\n",
    "# Simplify to a summary dataset, removing the bands dimension and reflectance data\n",
    "ds_summary = ds.drop_dims(\"bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Violin plots grouped by geohash\n",
    "ds_summary.hvplot.violin(\n",
    "    y=\"absorption_depth\",\n",
    "    by=\"geohash\",\n",
    ").opts(\n",
    "    opts.Violin(\n",
    "        width=800,\n",
    "        height=600,\n",
    "        xrotation=45,\n",
    "        show_legend=False,\n",
    "        title=\"Absorption Depth\",\n",
    "        ylim=(-0.02, 0.03),\n",
    "        violin_fill_color='absorption_depth',\n",
    "        cmap = 'Spectral_r',\n",
    "        clim = (0, 0.02),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking a threshold\n",
    "\n",
    "Here we're going to select water bodies (geohashes) by thresholding\n",
    "the absorption depth. First plot the absorption depths on a scatter plot.\n",
    "The x axis is just the waterbody's geohash, so it's meaningless.\n",
    "\n",
    "The following cell uses a threshold of 0.01, so selects the three\n",
    "waterbodies with a mean absorption_depth of above this and plots the\n",
    "spectra for these three waterbodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geohash_absorption_depths = ds_summary.groupby(\"geohash\").mean()\n",
    "\n",
    "geohash_absorption_depths.hvplot(\n",
    "    x=\"geohash\",\n",
    "    y=\"absorption_depth\",\n",
    "    kind=\"scatter\",\n",
    "    title=\"Mean absorption depth\",\n",
    "    color=\"absorption_depth\",\n",
    "    cmap = 'magma_r',\n",
    "    # Line color\n",
    "    line_color=\"grey\",\n",
    "    size=40,\n",
    "    xaxis=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_d_gt_001 = geohash_absorption_depths.where(geohash_absorption_depths.absorption_depth > 0.01, drop=True)\n",
    "high_absv = list(abs_d_gt_001.geohash.values)\n",
    "\n",
    "# Mean and std_dev plots\n",
    "color_cycle = hv.Cycle(\"Category20\")\n",
    "\n",
    "plots = []\n",
    "for geohash in high_absv:\n",
    "    row = water_summaries.sel(geohash=geohash)\n",
    "\n",
    "    plots.append(\n",
    "        (\n",
    "            hv.Spread(\n",
    "                row,\n",
    "                vdims=[\"mean\", \"std_dev\", \"std_dev\"],\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "            * hv.Curve(\n",
    "                row,\n",
    "                vdims=\"mean\",\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# Add a mean of all waterbodies plot too\n",
    "mean_all = water_summaries.mean(\"geohash\")\n",
    "plots.append(\n",
    "    (\n",
    "        hv.Spread(\n",
    "            mean_all,\n",
    "            vdims=[\"mean\", \"std_dev\", \"std_dev\"],\n",
    "            label=f\"all\"\n",
    "        )\n",
    "        * hv.Curve(\n",
    "            mean_all,\n",
    "            vdims=\"mean\",\n",
    "            label=f\"all\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "hv.Overlay(plots).opts(\n",
    "    opts.Spread(color=color_cycle, show_legend=True),\n",
    "    opts.Curve(color=color_cycle, show_legend=True),\n",
    "    opts.Overlay(\n",
    "        show_title=True, frame_width=600, frame_height=300, show_legend=True, yaxis=None\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alex Test Environment",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
