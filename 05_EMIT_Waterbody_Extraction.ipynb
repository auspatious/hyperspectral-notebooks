{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvplot.xarray  # noqa: F401\n",
    "import numpy as np\n",
    "from fsspec.implementations.http import HTTPFileSystem\n",
    "from dea_tools.spatial import xr_vectorize\n",
    "import geohash\n",
    "import folium\n",
    "import odc.geo.xr\n",
    "import geopandas as gpd\n",
    "from dea_tools.spatial import xr_rasterize\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import xarray as xr\n",
    "import json\n",
    "import shapely\n",
    "\n",
    "from emit_tools import emit_xarray\n",
    "from utils import get_rgb_dataset, get_earthdata_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See README.md for instructions on how to get an Earthdata token\n",
    "token = get_earthdata_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loading data can take around 3-4 minutes on a 100 Mbps connection\n",
    "\n",
    "# Refer to the README.md for instructions on how to find granule IDs\n",
    "granule = \"EMIT_L2A_RFL_001_20230316T045211_2307503_006\" # Canberra\n",
    "\n",
    "s3_url = \"s3://lp-prod-protected/EMITL2ARFL.001/\" + granule + \"/\" + granule + \".nc\"\n",
    "http_url = s3_url.replace(\"s3://\", \"https://data.lpdaac.earthdatacloud.nasa.gov/\")\n",
    "\n",
    "fs = HTTPFileSystem(headers={\n",
    "    \"Authorization\": f\"bearer {token}\"\n",
    "})\n",
    "ds = emit_xarray(fs.open(http_url))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up empty bands.\n",
    "ds = ds.fillna(np.nan).where(ds.reflectance!=-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a water layer\n",
    "high = ds.reflectance.sel(bands=450, method=\"nearest\")\n",
    "low = ds.reflectance.sel(bands=1275, method=\"nearest\")\n",
    "\n",
    "water = ((high - low) / (high + low)) > 0\n",
    "ds[\"water\"] = water.fillna(float(\"nan\")).where(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.water.hvplot(aspect=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIN_AREA = 1  # Hectares\n",
    "\n",
    "def add_geohash(row):\n",
    "    return geohash.encode(row.geometry.centroid.y, row.geometry.centroid.x, precision=9)\n",
    "\n",
    "    \n",
    "# Create polygons from the water layer\n",
    "water_polygons = xr_vectorize(ds.water, crs=\"epsg:4326\", mask=ds.water.values==1)\n",
    "water_polygons[\"area\"] = water_polygons.to_crs(\"epsg:3577\").area / 10000\n",
    "\n",
    "# Drop geopandas rows where the area is less than MIN_AREA\n",
    "water_polygons = water_polygons.drop(water_polygons[water_polygons['area'] < MIN_AREA].index)\n",
    "\n",
    "# Compute a geohash for each polygon at level 9\n",
    "geohashes = []\n",
    "for _, row in water_polygons.iterrows():\n",
    "    geohashes.append(add_geohash(row))\n",
    "\n",
    "water_polygons[\"geohash\"] = geohashes\n",
    "\n",
    "# # Add an ID row\n",
    "water_polygons['id'] = range(1, water_polygons.shape[0] + 1)\n",
    "\n",
    "# # Show us what we've got\n",
    "print(f\"Found {water_polygons.shape[0]} water polygons that are larger than {MIN_AREA} hectare(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the water layer on an interactive map\n",
    "m = folium.Map(control_scale=True, tiles=None)\n",
    "\n",
    "for _, row in water_polygons.iterrows():\n",
    "    geojson = folium.GeoJson(\n",
    "        data=json.dumps(shapely.geometry.mapping(row.geometry)),\n",
    "        style_function=lambda x: {\"fillColor\": \"blue\", \"Color\": \"blue\"},\n",
    "        tooltip=f\"{row.geohash}\"\n",
    "    )\n",
    "    folium.Popup(f\"<p><strong>geohash:</strong> {row.geohash}<br><strong>area:</strong> {row['area'] / 10000:.3f} Ha</p>\").add_to(\n",
    "        geojson\n",
    "    )\n",
    "    geojson.add_to(m)\n",
    "\n",
    "# Zoom map\n",
    "m.fit_bounds(ds.odc.map_bounds())\n",
    "\n",
    "tile = folium.TileLayer(\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name=\"Esri Satellite\",\n",
    "    control=True,\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rasterise the polygons again, so we can join on the geohash later\n",
    "water_raster = xr_rasterize(water_polygons, ds, attribute_col=\"id\", crs=\"epsg:4326\")\n",
    "\n",
    "# Join the rasterised polygons to the dataset\n",
    "ds[\"id\"] = xr.DataArray(water_raster, dims=(\"latitude\", \"longitude\"))\n",
    "\n",
    "# Create another empty array of strings\n",
    "ds[\"geohash\"] = xr.DataArray(\n",
    "      np.full((ds.latitude.size, ds.longitude.size), \"\", dtype=\"U9\"),\n",
    "      dims=(\"latitude\", \"longitude\"),\n",
    ")\n",
    "\n",
    "for _, row in water_polygons.iterrows():\n",
    "   # I think 'where' works the opposite of what you'd expect\n",
    "   ds[\"geohash\"] = ds.geohash.where(ds.id != row.id, row.geohash)\n",
    "\n",
    "# Mask the empty values\n",
    "ds[\"geohash\"] = ds.geohash.where(ds.geohash != \"\", drop=False)\n",
    "\n",
    "ds.geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "means = ds.groupby(\"geohash\").mean()\n",
    "std_dev = ds.groupby(\"geohash\").std()\n",
    "min = ds.groupby(\"geohash\").min()\n",
    "max = ds.groupby(\"geohash\").max()\n",
    "\n",
    "# Create a new dataset with the mean, standard deviation, min and max values\n",
    "# for each geohash\n",
    "water_summaries = xr.Dataset(\n",
    "    {\n",
    "        \"mean\": means.reflectance,\n",
    "        \"std_dev\": std_dev.reflectance,\n",
    "        \"min\": min.reflectance,\n",
    "        \"max\": max.reflectance,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Violin plots\n",
    "hv.Violin(water_summaries, \"geohash\", [\"mean\"], invert=True).opts(opts.Violin(width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean and min-max plots\n",
    "color_cycle = hv.Cycle(\"Category20\")\n",
    "\n",
    "plots = []\n",
    "for geohash in water_summaries.geohash.values:\n",
    "    row = water_summaries.sel(geohash=geohash)\n",
    "\n",
    "    plots.append(\n",
    "        (\n",
    "            hv.Spread(\n",
    "                row,\n",
    "                vdims=[\"min\", \"max\"],\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "            * hv.Curve(\n",
    "                row,\n",
    "                vdims=\"mean\",\n",
    "                label=f\"{geohash}\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "hv.Overlay(plots).opts(\n",
    "    opts.Spread(color=color_cycle),\n",
    "    opts.Curve(color=color_cycle),\n",
    "    opts.Overlay(\n",
    "        show_title=False, frame_width=600, show_legend=True, legend_position=\"bottom\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"width\": 600,\n",
    "    \"height\": 200,\n",
    "    \"show_legend\": False,\n",
    "    \"color\": color_cycle,\n",
    "}\n",
    "\n",
    "hv.Layout(plots).cols(1).opts(\n",
    "    opts.Curve(**options),\n",
    "    opts.Spread(**options),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alex Test Environment",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
